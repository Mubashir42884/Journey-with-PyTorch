{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tesnor Aggregations\n",
    "* Minimum (min)\n",
    "* Maximum (max)\n",
    "* Mean/Average (mean)\n",
    "* Summation (sum)\n",
    "* Positional Minima (argmin)\n",
    "* Positional Maxima (argmax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor X = \n",
      "tensor([  0,   5,  10,  15,  20,  25,  30,  35,  40,  45,  50,  55,  60,  65,\n",
      "         70,  75,  80,  85,  90,  95, 100, 105, 110, 115, 120, 125, 130, 135,\n",
      "        140, 145, 150, 155, 160, 165, 170, 175, 180, 185, 190, 195, 200, 205,\n",
      "        210, 215, 220, 225, 230, 235, 240, 245, 250, 255, 260, 265, 270, 275,\n",
      "        280, 285, 290, 295, 300, 305, 310, 315, 320, 325, 330, 335, 340, 345,\n",
      "        350, 355, 360, 365, 370, 375, 380, 385, 390, 395, 400, 405, 410, 415,\n",
      "        420, 425, 430, 435, 440, 445, 450, 455, 460, 465, 470, 475, 480, 485,\n",
      "        490, 495])\n",
      "Tensor X Shape = torch.Size([100])\n"
     ]
    }
   ],
   "source": [
    "# Create a tensor\n",
    "x = torch.arange(0, 500, 5)\n",
    "print(f\"Tensor X = \\n{x}\\nTensor X Shape = {x.shape}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Minimum (min)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minimum by x.min()\t: 0\n",
      "Minimum by torch.min(x)\t: 0\n"
     ]
    }
   ],
   "source": [
    "# Find the minimum (min)\n",
    "min = x.min()\n",
    "print(f'Minimum by x.min()\\t: {min}')\n",
    "min = torch.min(x)\n",
    "print(f'Minimum by torch.min(x)\\t: {min}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Maximum (max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum by x.max()\t: 495\n",
      "Maximum by torch.max(x)\t: 495\n"
     ]
    }
   ],
   "source": [
    "# Find the maximum (max)\n",
    "max = x.max()\n",
    "print(f'Maximum by x.max()\\t: {max}')\n",
    "max = torch.max(x)\n",
    "print(f'Maximum by torch.max(x)\\t: {max}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Mean/Average (mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "mean(): could not infer output dtype. Input dtype must be either a floating point or complex dtype. Got: Long",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m## Here we might see a dtype error for the first time. As mean() function \u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m## cannot work on long dtype, which is int64.\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m mean \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmean\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMean of Tensor X\u001b[39m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmean\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mRuntimeError\u001b[0m: mean(): could not infer output dtype. Input dtype must be either a floating point or complex dtype. Got: Long"
     ]
    }
   ],
   "source": [
    "## Here we might see a dtype error for the first time. As mean() function \n",
    "## cannot work on long dtype, which is int64.\n",
    "\n",
    "mean = torch.mean(x)\n",
    "print(f\"Mean of Tensor X\\t: {mean}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `torch.mean()` function requires a tensor of float32 dtype to work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean of Tensor X by torch.mean(dtype) :\t247.5\n",
      "Mean of Tensor X by x.mean(dtype) :\t247.5\n",
      "\n",
      "Mean of Tensor X by torch.mean(type) :\t247.5\n",
      "Mean of Tensor X by x.mean(type) : \t247.5\n"
     ]
    }
   ],
   "source": [
    "# To solve this error, we can trigger the optional dtype parameter of mean()\n",
    "\n",
    "mean = torch.mean(x, dtype=float)\n",
    "print(f\"Mean of Tensor X by torch.mean(dtype) :\\t{mean}\")\n",
    "mean = x.mean(dtype=float)\n",
    "print(f\"Mean of Tensor X by x.mean(dtype) :\\t{mean}\\n\")\n",
    "\n",
    "# OR\n",
    "\n",
    "mean = torch.mean(x.type(torch.float32))\n",
    "print(f\"Mean of Tensor X by torch.mean(type) :\\t{mean}\")\n",
    "mean = x.type(torch.float32).mean()\n",
    "print(f\"Mean of Tensor X by x.mean(type) : \\t{mean}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Summation (sum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summation by x.sum()\t\t: 24750\n",
      "Summation by torch.sum(x)\t: 24750\n"
     ]
    }
   ],
   "source": [
    "# Find the summation (sum)\n",
    "sum = x.sum()\n",
    "print(f'Summation by x.sum()\\t\\t: {sum}')\n",
    "sum = torch.sum(x)\n",
    "print(f'Summation by torch.sum(x)\\t: {sum}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Positional Minima (argmin) & Positional Maxima (argmax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Minimum Value is `0` and the index is `0`\n",
      "The Maximum Value is `495` and the index is `99`\n"
     ]
    }
   ],
   "source": [
    "# Find the index of the tensor with minimum and maximum value\n",
    "argmin = x.argmin()\n",
    "print(f\"The Minimum Value is `{x.min()}` and the index is `{argmin}`\")\n",
    "\n",
    "argmax = x.argmax()\n",
    "print(f\"The Maximum Value is `{x.max()}` and the index is `{argmax}`\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tensor Modifications\n",
    "* **Reshaping** - Reshapes an input tensor to a defined shape\n",
    "* **View** - Return a view of an input tensor of certain shape, but keep the original one\n",
    "* **Stacking** - Combine multiple tensors on top of each other\n",
    "    * Veertical Stack\n",
    "    * Horizontal Stack\n",
    "* **Squeezing** - Removes all in `1` dimension from a tensor \n",
    "* **Unsqueezing** - Add a `1` dimension to a target tensor\n",
    "* **Permute** - Return a view of the input with dimensions permuted (swapped) in a certain way"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([1., 2., 3., 4., 5., 6., 7., 8., 9.]), torch.Size([9]))"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's create a tensor\n",
    "a = torch.arange(1., 10.)\n",
    "a, a.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reshaping\n",
    "To reshape any tensor, we have to abide by two rules:\n",
    "* The multiplication of new shapes should be same as the original shape\n",
    "* The new shape should be a Multiplier of the original shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original :\n",
      " tensor([1., 2., 3., 4., 5., 6., 7., 8., 9.])\n",
      "Shape :\ttorch.Size([9])\n",
      "\n",
      "Reshaped (1 x 9):\n",
      " tensor([[1., 2., 3., 4., 5., 6., 7., 8., 9.]])\n",
      "Shape :\ttorch.Size([1, 9])\n",
      "\n",
      "Reshaped (3 x 3):\n",
      " tensor([[1., 2., 3.],\n",
      "        [4., 5., 6.],\n",
      "        [7., 8., 9.]])\n",
      "Shape :\ttorch.Size([3, 3])\n",
      "\n",
      "Reshaped (9 x 1):\n",
      " tensor([[1.],\n",
      "        [2.],\n",
      "        [3.],\n",
      "        [4.],\n",
      "        [5.],\n",
      "        [6.],\n",
      "        [7.],\n",
      "        [8.],\n",
      "        [9.]])\n",
      "Shape :\ttorch.Size([9, 1])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f\"Original :\\n {a}\\nShape :\\t{a.shape}\\n\")\n",
    "\n",
    "a_reshaped1 = a.reshape(1, 9)\n",
    "print(f\"Reshaped ({a_reshaped1.shape[0]} x {a_reshaped1.shape[1]}):\\n {a_reshaped1}\\nShape :\\t{a_reshaped1.shape}\\n\")\n",
    "\n",
    "a_reshaped2 = a.reshape(3, 3)\n",
    "print(f\"Reshaped ({a_reshaped2.shape[0]} x {a_reshaped2.shape[1]}):\\n {a_reshaped2}\\nShape :\\t{a_reshaped2.shape}\\n\")\n",
    "\n",
    "a_reshaped3 = a.reshape(9, 1)\n",
    "print(f\"Reshaped ({a_reshaped3.shape[0]} x {a_reshaped3.shape[1]}):\\n {a_reshaped3}\\nShape :\\t{a_reshaped3.shape}\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### View\n",
    "View is almost similar to Reshape. The difference is **Reshaping a tensor variable allots another new tensor in the memory, while Viewing a tensor variable shares the same original tensor in the memory**. This means, changing the View variable will ultimately change the original tensor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[1., 2., 3.],\n",
       "         [4., 5., 6.],\n",
       "         [7., 8., 9.]]),\n",
       " torch.Size([3, 3]))"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's change the view\n",
    "b = a.view(3,3)\n",
    "b, b.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[10.,  2.,  3.],\n",
       "         [10.,  5.,  6.],\n",
       "         [10.,  8.,  9.]]),\n",
       " tensor([10.,  2.,  3., 10.,  5.,  6., 10.,  8.,  9.]))"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's change the tensor variable `b` to see any change in variable `a`\n",
    "\n",
    "b[:, 0] = 10\n",
    "b, a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, the tensor variable `b`'s first index value was changed to `10` and we can see the original tensor variable `a`'s first index was also changed.<br>\n",
    "But notice how the shape and every positional index of tensor `b` has changed the original variable `a`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Stacking\n",
    "* **Vertical Stack (vstack) alias `row_stack`** - stacks each tensors vertically (row-wise)\n",
    "* **Horizontal Stack (hstack) alias `column_stack`** - stacks each tensors horizontally (column-wise)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Tensor:\ttensor([ 1, 11, 21, 31, 41, 51, 61, 71, 81, 91])\n",
      "Original Tensor Shape:\t(1, 10)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Stack tensors on top of each other\n",
    "x = torch.arange(1,100,10)\n",
    "print(f\"Original Tensor:\\t{x}\\nOriginal Tensor Shape:\\t{x.ndim, x.shape[0]}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "V-Stacked Tensor:\n",
      "tensor([[ 1, 11, 21, 31, 41, 51, 61, 71, 81, 91],\n",
      "        [ 1, 11, 21, 31, 41, 51, 61, 71, 81, 91],\n",
      "        [ 1, 11, 21, 31, 41, 51, 61, 71, 81, 91]])\n",
      "Tensor Shape:\ttorch.Size([3, 10])\n",
      "\n",
      "H-Stacked Tensor:\n",
      "tensor([ 1, 11, 21, 31, 41, 51, 61, 71, 81, 91,  1, 11, 21, 31, 41, 51, 61, 71,\n",
      "        81, 91,  1, 11, 21, 31, 41, 51, 61, 71, 81, 91])\n",
      "Tensor Shape:\ttorch.Size([30])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "x_stacked = torch.vstack([x,x,x]) # torch.row_stack([x,x,x])\n",
    "print(f\"V-Stacked Tensor:\\n{x_stacked}\\nTensor Shape:\\t{x_stacked.shape}\\n\")\n",
    "\n",
    "x_stacked = torch.hstack([x,x,x]) # torch.column_stack([x,x,x])\n",
    "print(f\"H-Stacked Tensor:\\n{x_stacked}\\nTensor Shape:\\t{x_stacked.shape}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stacked dim=0 Tensor:\n",
      "tensor([[ 1, 11, 21, 31, 41, 51, 61, 71, 81, 91],\n",
      "        [ 1, 11, 21, 31, 41, 51, 61, 71, 81, 91],\n",
      "        [ 1, 11, 21, 31, 41, 51, 61, 71, 81, 91]])\n",
      "Tensor Shape:\ttorch.Size([3, 10])\n",
      "\n",
      "Stacked dim=1 Tensor:\n",
      "tensor([[ 1,  1,  1],\n",
      "        [11, 11, 11],\n",
      "        [21, 21, 21],\n",
      "        [31, 31, 31],\n",
      "        [41, 41, 41],\n",
      "        [51, 51, 51],\n",
      "        [61, 61, 61],\n",
      "        [71, 71, 71],\n",
      "        [81, 81, 81],\n",
      "        [91, 91, 91]])\n",
      "Tensor Shape:\ttorch.Size([10, 3])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "x_stacked = torch.stack([x, x, x], dim=0)\n",
    "print(f\"Stacked dim=0 Tensor:\\n{x_stacked}\\nTensor Shape:\\t{x_stacked.shape}\\n\")\n",
    "\n",
    "x_stacked = torch.stack([x, x, x], dim=1)\n",
    "print(f\"Stacked dim=1 Tensor:\\n{x_stacked}\\nTensor Shape:\\t{x_stacked.shape}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Squeeze and Unsqueeze\n",
    "`torch.squeeze` removes all 1 dimension from a tensor<br>\n",
    "`torch.unsqueeze` adds a single dimension to a tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Tensor : \n",
      "tensor([ 1, 11, 21, 31, 41, 51, 61, 71, 81, 91])\n",
      "Shape : torch.Size([10])\n",
      "\n",
      "\n",
      "Reshaped Tensor : \n",
      "tensor([[ 1, 11, 21, 31, 41, 51, 61, 71, 81, 91]])\n",
      "Shape : torch.Size([1, 10])\n",
      "\n",
      "\n",
      "Squeezed Tensor : \n",
      "tensor([ 1, 11, 21, 31, 41, 51, 61, 71, 81, 91])\n",
      "Shape : torch.Size([10])\n",
      "\n",
      "\n",
      "Unsqueezed Tensor dim=0 : \n",
      "tensor([[ 1, 11, 21, 31, 41, 51, 61, 71, 81, 91]])\n",
      "Shape : torch.Size([1, 10])\n",
      "\n",
      "\n",
      "Unsqueezed Tensor dim=1 : \n",
      "tensor([[ 1],\n",
      "        [11],\n",
      "        [21],\n",
      "        [31],\n",
      "        [41],\n",
      "        [51],\n",
      "        [61],\n",
      "        [71],\n",
      "        [81],\n",
      "        [91]])\n",
      "Shape : torch.Size([10, 1])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f\"Original Tensor : \\n{x}\\nShape : {x.shape}\\n\")\n",
    "x_reshaped = x.reshape(1,10)\n",
    "print(f\"\\nReshaped Tensor : \\n{x_reshaped}\\nShape : {x_reshaped.shape}\\n\")\n",
    "\n",
    "x_squeezed = x_reshaped.squeeze()\n",
    "print(f\"\\nSqueezed Tensor : \\n{x_squeezed}\\nShape : {x_squeezed.shape}\\n\")\n",
    "\n",
    "x_unsqueezed = x_squeezed.unsqueeze(dim=0)\n",
    "print(f\"\\nUnsqueezed Tensor dim=0 : \\n{x_unsqueezed}\\nShape : {x_unsqueezed.shape}\\n\")\n",
    "\n",
    "x_unsqueezed = x_squeezed.unsqueeze(dim=1)\n",
    "print(f\"\\nUnsqueezed Tensor dim=1 : \\n{x_unsqueezed}\\nShape : {x_unsqueezed.shape}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Permute\n",
    "`torch.permute()` returns a view of the original tensor `input` with its dimension permuted (swapped)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Previous Image Shape : torch.Size([224, 224, 3])\n",
      "Permuted Image Tensor :\n",
      " tensor([[[0.2767, 0.8531, 0.9216,  ..., 0.2231, 0.8482, 0.0695],\n",
      "         [0.5313, 0.5851, 0.9939,  ..., 0.9300, 0.0031, 0.0762],\n",
      "         [0.1663, 0.5802, 0.4238,  ..., 0.8256, 0.2081, 0.2557],\n",
      "         ...,\n",
      "         [0.6558, 0.1014, 0.3109,  ..., 0.6864, 0.4144, 0.8503],\n",
      "         [0.6778, 0.3108, 0.2122,  ..., 0.4678, 0.7675, 0.3764],\n",
      "         [0.4796, 0.7514, 0.1595,  ..., 0.7988, 0.2960, 0.1693]],\n",
      "\n",
      "        [[0.8730, 0.4989, 0.1346,  ..., 0.5951, 0.1721, 0.7872],\n",
      "         [0.5796, 0.6862, 0.8995,  ..., 0.8133, 0.2002, 0.7135],\n",
      "         [0.5267, 0.9734, 0.3419,  ..., 0.1677, 0.8896, 0.1285],\n",
      "         ...,\n",
      "         [0.0052, 0.0590, 0.6771,  ..., 0.9455, 0.1797, 0.8420],\n",
      "         [0.6533, 0.9132, 0.8192,  ..., 0.0965, 0.5183, 0.2370],\n",
      "         [0.0708, 0.1032, 0.3494,  ..., 0.2658, 0.6531, 0.6453]],\n",
      "\n",
      "        [[0.3161, 0.1232, 0.1203,  ..., 0.9517, 0.4038, 0.1736],\n",
      "         [0.1839, 0.2240, 0.2866,  ..., 0.0039, 0.8117, 0.6083],\n",
      "         [0.7039, 0.2528, 0.5736,  ..., 0.8356, 0.4032, 0.0902],\n",
      "         ...,\n",
      "         [0.3143, 0.5621, 0.9362,  ..., 0.5355, 0.4306, 0.2249],\n",
      "         [0.5127, 0.6243, 0.5002,  ..., 0.6643, 0.2849, 0.9010],\n",
      "         [0.3571, 0.4506, 0.6289,  ..., 0.6903, 0.2795, 0.9633]]])\n",
      "\n",
      "Permuted Image Shape : torch.Size([3, 224, 224])\n"
     ]
    }
   ],
   "source": [
    "# A image tensor with [(height, width, channel)]\n",
    "img = torch.rand(size=(224,224,3)) # Tensor index = (0, 1, 2)\n",
    "\n",
    "# Permute the original image tensor to rearrange the axis (or dim) order\n",
    "img_permuted = img.permute(2, 0, 1) # shifts axis 0->1, 1->2, 2->0\n",
    "\n",
    "print(f\"Previous Image Shape : {img.shape}\")\n",
    "print(f\"Permuted Image Tensor :\\n {img_permuted}\\n\")\n",
    "print(f\"Permuted Image Shape : {img_permuted.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Previous Original Tensor[0,0,0] Value :\t0.276655375957489\n",
      "Previous Permuted Tensor[0,0,0] Value :\t0.276655375957489\n",
      "Updated Original Tensor[0,0,0] Value :\t123456.0\n",
      "Updated Permuted Tensor[0,0,0] Value :\t123456.0\n"
     ]
    }
   ],
   "source": [
    "# Extras\n",
    "print(f\"Previous Original Tensor[0,0,0] Value :\\t{img[0,0,0]}\")\n",
    "print(f\"Previous Permuted Tensor[0,0,0] Value :\\t{img_permuted[0,0,0]}\")\n",
    "\n",
    "img[0,0,0] = 123456.\n",
    "img_permuted = img.permute(2, 0, 1)\n",
    "\n",
    "print(f\"Updated Original Tensor[0,0,0] Value :\\t{img[0,0,0]}\")\n",
    "print(f\"Updated Permuted Tensor[0,0,0] Value :\\t{img_permuted[0,0,0]}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tensor Indexing : Selecting Data From Tensors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The tensor shape belongs to three properties:\n",
    "- Element: The element in each index of the tensor\n",
    "- Index: The index of tensor in a dimension\n",
    "- Tensor: The tensor itself\n",
    "</br></br>\n",
    "*Tensor Shape([Number of Tensors, Number of Indices, Number of Elements])*\n",
    "</br>\n",
    "As per the shape of tensor: <br>`tensor.shape([1,3,3]) = tensor.shape([1 Tensor, 3 Index, 3 Elements])`\n",
    "\n",
    "<img src=\"../resources/Tensor_Indexing.jpg\" width=85%></img>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Tensor:\n",
      " tensor([[[1, 2, 3],\n",
      "         [4, 5, 6],\n",
      "         [7, 8, 9]]])\n",
      "Shape:\ttorch.Size([1, 3, 3])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create a Tensor\n",
    "import torch\n",
    "\n",
    "x = torch.arange(1, 10).reshape(1,3,3)\n",
    "print(f\"Original Tensor:\\n {x}\\nShape:\\t{x.shape}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 2, 3],\n",
       "        [4, 5, 6],\n",
       "        [7, 8, 9]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Index the tensor in 0-th dimension (dim=0)\n",
    "x[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It gives the zeroth tensor at the zeroth dimension of the whole tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 2, 3])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Index the tensor in 1st dimension (dim=1)\n",
    "x[0][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It gives the zeroth index of the zeroth tensor at the zeroth dimension of the whole tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Index the tensor in 2nd dimension (dim=2) [last dimension]\n",
    "x[0][0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2nd Index of the Zeroth Tensor: tensor([4, 5, 6])\n",
      "\n",
      "3rd Element of the 1st Index of the Zeroth Tensor: 3\n",
      "\n",
      "Last Element of the last Index of the Zeroth Tensor: 9\n",
      "\n",
      "3rd Index of the Zeroth Tensor: tensor([7, 8, 9])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Let's index some more tensor\n",
    "\n",
    "print(f\"2nd Index of the Zeroth Tensor: {x[0][1]}\\n\")\n",
    "print(f\"3rd Element of the 1st Index of the Zeroth Tensor: {x[0][0][2]}\\n\")\n",
    "print(f\"Last Element of the last Index of the Zeroth Tensor: {x[0][2][2]}\\n\")\n",
    "print(f\"3rd Index of the Zeroth Tensor: {x[0][2]}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 1,  2,  3],\n",
      "         [ 4,  5,  6],\n",
      "         [ 7,  8,  9]],\n",
      "\n",
      "        [[10, 11, 12],\n",
      "         [13, 14, 15],\n",
      "         [16, 17, 18]]]) \n",
      " torch.Size([2, 3, 3])\n",
      "\n",
      "\n",
      "Select all the tensor's zeroth indices = x[:, 0]\n",
      "tensor([[ 1,  2,  3],\n",
      "        [10, 11, 12]])\n",
      "\n",
      "Select all the tensor's 2nd index's 2nd elements = x[:,1,2]\n",
      "tensor([ 6, 15])\n",
      "\n",
      "Select 2nd tensor's 1st index's al elements = x[1,0,:]\n",
      "tensor([10, 11, 12])\n",
      "\n",
      "Select all tensor's all indices last element = x[:, :,-1]\n",
      "tensor([[ 3,  6,  9],\n",
      "        [12, 15, 18]])\n",
      "\n",
      "Select last tensor's last index's last element = x[-1,-1,-1]\n",
      "18\n",
      "\n",
      "Select 1st tensor's all indices last elements = x[0,:,-1]\n",
      "tensor([3, 6, 9])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# You can also use \":\" to select \"all\" of the targeted dimension\n",
    "x = torch.arange(1, 19).reshape(2,3,3)\n",
    "\n",
    "print(x, \"\\n\", x.shape)\n",
    "print(f\"\\n\\nSelect all the tensor's zeroth indices = x[:, 0]\\n{x[:, 0]}\\n\")\n",
    "print(f\"Select all the tensor's 2nd index's 2nd elements = x[:,1,2]\\n{x[:,1,2]}\\n\")\n",
    "print(f\"Select 2nd tensor's 1st index's al elements = x[1,0,:]\\n{x[1,0,:]}\\n\")\n",
    "print(f\"Select all tensor's all indices last element = x[:, :,-1]\\n{x[:, :,-1]}\\n\")\n",
    "print(f\"Select last tensor's last index's last element = x[-1,-1,-1]\\n{x[-1,-1,-1]}\\n\")\n",
    "print(f\"Select 1st tensor's all indices last elements = x[0,:,-1]\\n{x[0,:,-1]}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It  gives the zeroth element of the zeroth index's zeroth tensor at the zeroth dimension of the whole tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 align=\"center\">--< THE END >--</h1> \n",
    "@MUBA"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Pytorch (CUDA)",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
