{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tensors & Numpy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NumPy is generally used to express data in scientific computation and PyTorch has its own functionality to interact with NumPy.\n",
    "* Data in NumPy, want to convert into PyTorch Tensor --> `torch.from_numpy(ndarray)`\n",
    "* Data in Tensor, want to convert into Numpy Array --> `torch.Tensor.numpy()`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tensor --> Numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numpy Array:\t[1. 2. 3. 4. 5. 6. 7.]\n",
      "Torch Tensor:\ttensor([1., 2., 3., 4., 5., 6., 7.], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np \n",
    "\n",
    "# Create an array in Numpy\n",
    "array = np.arange(1.,8.)\n",
    "tensor = torch.from_numpy(array)\n",
    "\n",
    "print(f\"Numpy Array:\\t{array}\\nTorch Tensor:\\t{tensor}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Numpy --> Tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Torch Tensor:\ttensor([1., 1., 1., 1., 1.])\n",
      "Numpy Array:\t[1. 1. 1. 1. 1.]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tensor = torch.ones(5)\n",
    "array = tensor.numpy()\n",
    "\n",
    "print(f\"Torch Tensor:\\t{tensor}\\nNumpy Array:\\t{array}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** **Note For Use** **<br>\n",
    "The default dtype of tensor is `float64` and the default dtype of numpy is `float32`. So, while converting them, please make sure which dtype are you going to use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numpy Array:\t(array([1., 1., 1., 1., 1.], dtype=float32), dtype('float32'))\n",
      "Torch Tensor:\t(tensor([1., 1., 1., 1., 1.]), torch.float32)\n"
     ]
    }
   ],
   "source": [
    "# Let's reconvert the numpy array to a tensor\n",
    "tensor = torch.from_numpy(array)\n",
    "array = tensor.numpy()\n",
    "\n",
    "print(f\"Numpy Array:\\t{array, array.dtype}\\nTorch Tensor:\\t{tensor, tensor.dtype}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PyTorch Reproducibility\n",
    "To reuce the randomness of random tensors using `RANDOM_SEED`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor A:\n",
      "tensor([[0.8548, 0.0240, 0.4702, 0.1620],\n",
      "        [0.5360, 0.4982, 0.6276, 0.0910],\n",
      "        [0.2159, 0.0260, 0.9612, 0.7533],\n",
      "        [0.7190, 0.4091, 0.2797, 0.6428]])\n",
      "Tensor B:\n",
      "tensor([[0.3312, 0.5153, 0.2986, 0.8596],\n",
      "        [0.8950, 0.9578, 0.7068, 0.4536],\n",
      "        [0.2630, 0.9686, 0.8441, 0.0318],\n",
      "        [0.3516, 0.6056, 0.8034, 0.7945]])\n",
      "Check Equality:\n",
      "tensor([[False, False, False, False],\n",
      "        [False, False, False, False],\n",
      "        [False, False, False, False],\n",
      "        [False, False, False, False]])\n"
     ]
    }
   ],
   "source": [
    "tensorA = torch.rand(4,4)\n",
    "tensorB = torch.rand(4,4)\n",
    "\n",
    "print(f\"Tensor A:\\n{tensorA}\\nTensor B:\\n{tensorB}\\nCheck Equality:\")\n",
    "print(tensorA == tensorB)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With normal tensors without `random seed` it shows complete randomness while producing random tensors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor C:\n",
      "tensor([[0.2961, 0.5166, 0.2517, 0.6886],\n",
      "        [0.0740, 0.8665, 0.1366, 0.1025],\n",
      "        [0.1841, 0.7264, 0.3153, 0.6871],\n",
      "        [0.0756, 0.1966, 0.3164, 0.4017]])\n",
      "Tensor D:\n",
      "tensor([[0.2961, 0.5166, 0.2517, 0.6886],\n",
      "        [0.0740, 0.8665, 0.1366, 0.1025],\n",
      "        [0.1841, 0.7264, 0.3153, 0.6871],\n",
      "        [0.0756, 0.1966, 0.3164, 0.4017]])\n",
      "Check Equality:\n",
      "tensor([[True, True, True, True],\n",
      "        [True, True, True, True],\n",
      "        [True, True, True, True],\n",
      "        [True, True, True, True]])\n"
     ]
    }
   ],
   "source": [
    "# Set the random seed\n",
    "RANDOM_SEED = 123\n",
    "torch.manual_seed(RANDOM_SEED)\n",
    "tensorC = torch.rand(4,4)\n",
    "torch.manual_seed(RANDOM_SEED)\n",
    "tensorD = torch.rand(4,4)\n",
    "\n",
    "print(f\"Tensor C:\\n{tensorC}\\nTensor D:\\n{tensorD}\\nCheck Equality:\")\n",
    "print(tensorC == tensorD)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Running Tensors on GPUs\n",
    "\n",
    "GPUs make faster and lighter computations on numbers by using `CUDA` with `NVIDIA` hardware."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# GPU Access check\n",
    "import torch\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device:\tcuda\n"
     ]
    }
   ],
   "source": [
    "# Setup device agnostic code\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Device:\\t{device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Count the number of active GPUs\n",
    "torch.cuda.device_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor:\ttensor([1, 2, 3])\n",
      "Device:\tcpu\n"
     ]
    }
   ],
   "source": [
    "# Putting tensors (and models) on the GPU\n",
    "import torch\n",
    "tensor = torch.tensor([1,2,3]) # By default device is on CPU\n",
    "print(f\"Tensor:\\t{tensor}\\nDevice:\\t{tensor.device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor:\ttensor([1, 2, 3], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "# Move tensor to GPU (if available)\n",
    "tensor_on_gpu = tensor.to(device)\n",
    "print(f\"Tensor:\\t{tensor_on_gpu}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Moving tensors back to CPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "can't convert cuda:0 device type tensor to numpy. Use Tensor.cpu() to copy the tensor to host memory first.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Tensors cannot transform tensors on GPUs, therefore error will occur\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[43mtensor_on_gpu\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnumpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mTypeError\u001b[0m: can't convert cuda:0 device type tensor to numpy. Use Tensor.cpu() to copy the tensor to host memory first."
     ]
    }
   ],
   "source": [
    "# Tensors cannot transform tensors on GPUs, therefore error will occur\n",
    "tensor_on_gpu.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor on CPU in Numpy: \t[1 2 3]\n",
      "Tensor on GPU in PyTorch:\ttensor([1, 2, 3], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "# To fix the GPU tensor with NumPy issue, we can set it to the CPU\n",
    "\n",
    "tensor_back_on_cpu = tensor_on_gpu.cpu().numpy()\n",
    "print(f\"Tensor on CPU in Numpy: \\t{tensor_back_on_cpu}\")\n",
    "print(f\"Tensor on GPU in PyTorch:\\t{tensor_on_gpu}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 align=\"center\">--< THE END >--</h1> \n",
    "@MUBA"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Pytorch (CUDA)",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
